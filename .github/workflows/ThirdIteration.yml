# Workflow for the 3rd scraping iteration process

# Whenever pull request is made targeting branch initialisation, csv is reset
name: third-iteration

# Workflow's description
run-name: Scrape the products in daily errors (2nd iteration) and store raw data 

# Function to schedule the time (UTC), day, month, and year of the workflow process
on:
  schedule:
    - cron: '11 11 * * *' #UTC time
  #workflow_dispatch: # Allows manual testing
  
#on:
#  pull_request:
#    # Sequence of patterns matched against refs/heads
#    branches:
#      - third-iteration
#      - third-iteration   

jobs:
  getdataandrefreshmap:
    runs-on: ubuntu-latest
    steps:
      # It checks out the latest content of your repository
      - name: Checkout repo content
        uses: actions/checkout@v3 # checkout the repository content to github runner.
        with:
          fetch-depth: 0
      - name: Setup python
        uses: actions/setup-python@v4
        with:
          python-version: 3.9 #install the python needed
      - name: Upgrade pip
        run: pip install --upgrade pip
      # Installs the required Python dependencies
      - name: Install dependencies
        run: |
          if [ -f requirements.txt ]; then pip install --no-cache-dir -r requirements.txt; fi
      - name: Run ThirdIteration.py
        run: |
          python PythonCodes/ThirdIteration.py
          git status
          git config user.name github-actions
          git config user.email github-actions@github.com
          git add .
          git commit -m "3rd scraping iteration completed"
          git push origin HEAD:main
